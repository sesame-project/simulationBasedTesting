{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80376a13-5729-49e7-830c-e2a0ec7c9667",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from itertools import chain,combinations\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import sys\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import time\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1087befa-4e03-419a-b12c-162ddf3d17bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def powerset(iterable):\n",
    "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3653f087-5d37-4ea2-b355-2c383f53d57d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def delete_edges_from(graph, vertex):\n",
    "    e = graph.adj[vertex]\n",
    "    for linked in list(e):\n",
    "        graph.remove_edge(vertex,linked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97301b5f-603b-45c2-8e54-a0f9617c1fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_metric_func(graph):\n",
    "    return list(graph.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a961be0-1cf9-4ad5-9d6e-f22a27591197",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_metric_ranking(rankings, num):\n",
    "    return rankings.index(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0901e002-60c3-417a-98f4-bcf5929b63a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Eqn 2 in diversification paper\n",
    "def calc_compdist_from(graph, i, j, lam):\n",
    "    \n",
    "    dimension_dist = 0\n",
    "    i_props = graph.nodes[i]\n",
    "    j_props = graph.nodes[j]\n",
    "    ranking_i = i_props['m0']\n",
    "    ranking_j = j_props['m0']\n",
    "    #print(\"ranking_i\" + str(ranking_i))\n",
    "    #print(\"ranking_j\" + str(ranking_j))\n",
    "    \n",
    "    # Get the properties\n",
    "    for k,v in i_props.items():\n",
    "        # Dimension values only\n",
    "        if k.startswith(\"d\"):\n",
    "            dist = (v - j_props[k])\n",
    "            dimension_dist += (dist ** 2.0)\n",
    "            \n",
    "    comp_value = ranking_i + ranking_j + 2 * lam * np.sqrt(dimension_dist)\n",
    "    #print(\"dimension_dist = \" + str(dimension_dist))\n",
    "    #print(\"comp_value = \" + str(comp_value))\n",
    "    return comp_value\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdf5064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_weight_edge(sim_graph, lam):\n",
    "    max_weight = -1\n",
    "    tu = 0\n",
    "    tv = 0\n",
    "    vertex_count = sim_graph.number_of_nodes()\n",
    "    for u in range(0,vertex_count):\n",
    "        linked_nodes = sim_graph.adj[u]\n",
    "        for v in list(linked_nodes):\n",
    "            w = calc_compdist_from(sim_graph, u, v, lam)\n",
    "            #print(\"u=\"+str(u) + \",\" + str(v) + \",weight=\" + str(w))\n",
    "            if (w > max_weight):\n",
    "                tu = u\n",
    "                tv = v\n",
    "                max_weight = w\n",
    "    return tu,tv, max_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ba1851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_weight_selected_nodes(simgraph, nodes,lam):\n",
    "    total_weight = 0\n",
    "    for i in nodes:\n",
    "        for j in nodes:\n",
    "            total_weight += calc_compdist_from(simgraph, i, j, lam)\n",
    "            \n",
    "    return total_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237e8bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nx.Graph()\n",
    "a.add_node(5)\n",
    "a.add_node(7)\n",
    "a.add_node(4)\n",
    "a.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac193c7-f3c1-436e-a1b7-d6ae99d75f3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Need to add arbitrary vertex\n",
    "def max_sum_divergence_approx(sim_graph, phy_count, lam):\n",
    "    Phy = nx.Graph() \n",
    "    lim = int(np.floor(phy_count/2))\n",
    "    for i in range(0,lim):\n",
    "        mu, mv, weight = find_max_weight_edge(sim_graph, lam)\n",
    "        if (mu != mv):\n",
    "            print(\"Max weight: \" + str(mu) + \"->\" + str(mv) + \",weight=\" + str(weight))\n",
    "            Phy.add_node(mu)\n",
    "            Phy.add_node(mv)\n",
    "            Phy.add_edge(mu,mv)\n",
    "            print(\"Number of nodes in Phy=\" + str(Phy.number_of_nodes()))\n",
    "            # remove other connected edges from mu and mv in the sim_graph\n",
    "            delete_edges_from(sim_graph, mu)\n",
    "            delete_edges_from(sim_graph, mv)\n",
    "            # check further\n",
    "        \n",
    "    # If phy_count is odd, add a random vertex\n",
    "    # for now, only use an even phy_count\n",
    "    \n",
    "    total_weight = get_total_weight_selected_nodes(sim_graph, Phy.nodes ,lam)\n",
    "    return Phy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe01e35-6417-4c6b-bb96-b21992e1e8c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gen_node_props(metrics_count, dim_count, metric_max, dim_max):\n",
    "    nodeprops = {}\n",
    "    metrics = []\n",
    "    \n",
    "    for di in range(0, dim_count):\n",
    "        rand_dim = np.random.uniform(low=0, high=dim_max)\n",
    "        nodeprops[\"d\" + str(di)] = rand_dim\n",
    "        \n",
    "    # Generate the metrics\n",
    "    for mi in range(0,metrics_count):\n",
    "        rand_metric = np.random.uniform(low=0, high=metric_max)\n",
    "        metrics.append(rand_metric)\n",
    "        nodeprops[\"m\" + str(mi)] = rand_metric\n",
    "    return nodeprops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2764ab6-cf98-415a-b1a2-62f8c56ceb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_sim_graph(node_count, metric_count, metric_max, dim_count, dim_max):\n",
    "    sim = nx.Graph();\n",
    "    for i in range(0,node_count):\n",
    "        sim.add_nodes_from([(i, gen_node_props(metric_count, dim_count, metric_max, dim_max))])\n",
    "        \n",
    "    for i in range(0, node_count):\n",
    "        for j in range(0, node_count):\n",
    "            if (i != j):\n",
    "                sim.add_edge(i,j)\n",
    "\n",
    "    print(\"Edges: = \" + str(sim.number_of_edges()))\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bde2d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_node_props_from_dataframe(data, i, chosen_dimensions):\n",
    "    # map the selected columns in chosen_dimensions into 'd0'\n",
    "    dim_num = 0\n",
    "    node_props = {}\n",
    "    for d in chosen_dimensions:\n",
    "        dim_id = \"d\" + str(dim_num)\n",
    "        node_props[dim_id] = data.loc[i, d]\n",
    "        dim_num += 1\n",
    "    node_props['m0'] = data.loc[i, \"METRIC_Q\"]\n",
    "    node_props['NAME'] = data.loc[i, \"NAME\"]\n",
    "    \n",
    "    # Set flag if it is on the pareto front\n",
    "    node_props[\"TESTTAG\"] = data.loc[i, \"TESTTAG\"]        \n",
    "    return node_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff97d49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sim_graph_from_data(filename_csv, chosen_dimensions):\n",
    "    sim = nx.Graph();\n",
    "    data = pd.read_csv(filename_csv)\n",
    "    node_count = len(data)\n",
    "    for i in range(0,node_count):\n",
    "        sim.add_nodes_from([(i, read_node_props_from_dataframe(data, i, chosen_dimensions))])\n",
    "        \n",
    "    for i in range(0, node_count):\n",
    "        for j in range(0, node_count):\n",
    "            if (i != j):\n",
    "                sim.add_edge(i,j)\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a12882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_dim_boundaries_if_needed(boundaries, dim_id, value):\n",
    "    if dim_id in boundaries:\n",
    "        interval = boundaries[dim_id]\n",
    "        if not (value in interval):\n",
    "            if value < interval.left:\n",
    "                boundaries[dim_id] = pd.Interval(value, interval.right)\n",
    "            if value > interval.right:\n",
    "                boundaries[dim_id] = pd.Interval(interval.left, value)\n",
    "    else:\n",
    "        boundaries[dim_id] = pd.Interval(value,value, 'both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f87a957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maximum and minimum of particular dimensions\n",
    "def find_dimensional_boundaries(simgraph):\n",
    "    boundaries = {}\n",
    "    node_count = len(simgraph.nodes)\n",
    "    for i in range(0, node_count):\n",
    "        for k,v in simgraph.nodes[i].items():\n",
    "            if k.startswith(\"d\"):\n",
    "                extend_dim_boundaries_if_needed(boundaries, k, v)\n",
    "    return boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dacd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_value(bound_interval,v):\n",
    "    return (v - bound_interval.left) / bound_interval.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac4588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_dimensions(simgraph):\n",
    "    boundaries = find_dimensional_boundaries(simgraph)\n",
    "    simgraph_out = nx.Graph()\n",
    "    node_count = len(simgraph.nodes())\n",
    "    for i in range(0, node_count):\n",
    "        new_props = {}\n",
    "        for k,v in simgraph.nodes[i].items():\n",
    "            if k.startswith(\"d\"):\n",
    "                bound_interval = boundaries[k]\n",
    "                new_props[k] = normalise_value(bound_interval, v)\n",
    "            else:\n",
    "                new_props[k] = v\n",
    "                \n",
    "        simgraph_out.add_nodes_from([(i, new_props)])\n",
    "                \n",
    "    for i in range(0, node_count):\n",
    "        for j in range(0, node_count):\n",
    "            if (i != j):\n",
    "                simgraph_out.add_edge(i,j)\n",
    "                \n",
    "    return simgraph_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996e17a0-a5e9-43aa-b2b4-dd1e425ce7db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: simple ranking function is the sum of the metrics\n",
    "# TODO: metrics would need to be scaled somehow\n",
    "def ranking_func(graph,node_id):\n",
    "    props = graph.nodes[node_id]\n",
    "    total = 0\n",
    "    for k,v in props.items():\n",
    "        if \"m\" in k:\n",
    "            total += v\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59953d9-50a5-453c-a526-fc5832828ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dist_sum theoretical max = k * (k-1) * sqrt(param_space_num_dimesions)\n",
    "# assuming all dimensions are properly normalised from zero to one!\n",
    "\n",
    "# weight_sum theortical max = k * max_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887e90cb-22ae-4bf1-8a6a-a0e4d55e8b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounding_box_all_dimensions_volume(graph, node_set):\n",
    "\n",
    "    max_dists_by_dim = {}\n",
    "    max_dist_points = {}\n",
    "\n",
    "    # Need to override the product to zero when no nodes involved\n",
    "    if np.size(node_set) > 0:\n",
    "        product = 1\n",
    "    else:\n",
    "        product = 0\n",
    "    \n",
    "    for ni in node_set:\n",
    "        for nj in node_set:\n",
    "            i_props = graph.nodes[ni]\n",
    "            j_props = graph.nodes[nj]\n",
    "            # Dimension values only\n",
    "            for k,v in i_props.items():\n",
    "                if k.startswith(\"d\"):\n",
    "                    dist_dim = np.abs(v - j_props[k])\n",
    "                    print(k,ni,nj,dist_dim)\n",
    "                    if (not (k in max_dists_by_dim)):\n",
    "                        max_dists_by_dim[k] = dist_dim\n",
    "                    else:\n",
    "                        if (dist_dim > max_dists_by_dim[k]):\n",
    "                            max_dists_by_dim[k] = dist_dim\n",
    "                            max_dist_points[k] = (ni,nj)\n",
    "                        \n",
    "\n",
    "    for d in max_dists_by_dim.values():\n",
    "        product *= d\n",
    "    \n",
    "    return (product, max_dists_by_dim, max_dist_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a303fc32-07a2-4061-8931-3cbc7029440e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounding_box_perimeter_sum(graph, node_set):\n",
    "\n",
    "    max_dists_by_dim = {}\n",
    "    max_dist_points = {}\n",
    "\n",
    "    sum = 0\n",
    "    \n",
    "    for ni in node_set:\n",
    "        for nj in node_set:\n",
    "            i_props = graph.nodes[ni]\n",
    "            j_props = graph.nodes[nj]\n",
    "            # Dimension values only\n",
    "            for k,v in i_props.items():\n",
    "                if k.startswith(\"d\"):\n",
    "                    dist_dim = np.abs(v - j_props[k])\n",
    "                    print(k,ni,nj,dist_dim)\n",
    "                    if (not (k in max_dists_by_dim)):\n",
    "                        max_dists_by_dim[k] = dist_dim\n",
    "                    else:\n",
    "                        if (dist_dim > max_dists_by_dim[k]):\n",
    "                            max_dists_by_dim[k] = dist_dim\n",
    "                            max_dist_points[k] = (ni,nj)\n",
    "                        \n",
    "\n",
    "    for d in max_dists_by_dim.values():\n",
    "        sum += d\n",
    "    \n",
    "    return (sum, max_dists_by_dim, max_dist_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7cfd67-e0e5-4520-bd7a-8a2a6304e776",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_subset_value_function(graph, dim_count, subset_inds, lam):\n",
    "    k = len(subset_inds)\n",
    "    weight_sum = 0\n",
    "    for ni in subset_inds:\n",
    "    # ranking_func is w in the equation\n",
    "        weight_sum += ranking_func(graph, ni)\n",
    "    \n",
    "    # Are we double counting the distance here?\n",
    "    # dist_sum has to be normalised over the number of dimensions?\n",
    "    # the 2 is to compensate for counting them only once?\n",
    "    # not needed here?\n",
    "    dist_sum = 0\n",
    "    for ni in subset_inds:\n",
    "        for nj in subset_inds:\n",
    "            dist_sum += dist_func(graph, ni,nj)\n",
    "            \n",
    "    dist_sum_scaled = dist_sum / np.sqrt(dim_count) \n",
    "    print(subset_inds, dist_sum_scaled, weight_sum, dist_sum_scaled)\n",
    "    bounding_box_vol, _, _ = bounding_box_all_dimensions_volume(graph, subset_inds)\n",
    "\n",
    "    # Removing the 2 factor here, since we are counting across all possible NxN combinations above\n",
    "    total = (1-lam)*(k-1)*weight_sum + lam*dist_sum_scaled\n",
    "    return total, weight_sum, dist_sum_scaled, bounding_box_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe3e92f-425f-4c37-af90-15a21ce09665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_func(graph, ni, nj):\n",
    "    i_props = graph.nodes[ni]\n",
    "    j_props = graph.nodes[nj]\n",
    "    dimension_dist = 0.0\n",
    "    for k,v in i_props.items():\n",
    "    # Dimension values only\n",
    "        if k.startswith(\"d\"):\n",
    "            dist = (v - j_props[k])\n",
    "            dimension_dist += (dist ** 2.0)\n",
    "            #print(\"Adding dist contribution: \", k, v)\n",
    "    return np.sqrt(dimension_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5af5379-8078-4c39-a5fc-67845d75dba4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def subset_cost(subset):\n",
    "    return len(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9f8ef3-0b42-43f5-8045-ad3d224aeaba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def meets_cost_constraint(subset, max_cost):\n",
    "    return (subset_cost(subset) <= max_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f109760-e3eb-4243-829e-5f8eb8e86452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsets_viable_sorted_by_cost(simgraph, lam):\n",
    "    all_subsets = list(powerset(simgraph.nodes()))\n",
    "    viable_subsets = filter(meets_cost_constraint, all_subsets)\n",
    "    subset_info = map(lambda subset: (subset, subset_value(simgraph, subset, lam)), viable_subsets)\n",
    "    return sorted(subset_info, key=lambda info: info[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dcc695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_subset_via_powerset(simgraph, dim_count, lam, max_cost):\n",
    "    all_subsets = list(powerset(simgraph.nodes()))\n",
    "    max_val = 0\n",
    "    best_ranking_sum = 0\n",
    "    best_dist_sum = 0\n",
    "    best_subset = None\n",
    "    best_boundbox_vol = 0\n",
    "    all_subset_rankings = []\n",
    "    \n",
    "    for p in tqdm(all_subsets):\n",
    "        if meets_cost_constraint(p, max_cost):\n",
    "            v, ranking_sum, dist_sum, bounding_box_vol = calc_subset_value_function(simgraph, dim_count, p, lam)\n",
    "            all_subset_rankings.append(p, v, ranking_sum, dist_sum, bounding_box_vol))\n",
    "            if v > max_val:\n",
    "                max_val = v\n",
    "                best_subset = p\n",
    "                best_ranking_sum = ranking_sum\n",
    "                best_dist_sum = dist_sum\n",
    "                best_boundbox_val = bounding_box_vol\n",
    "    return (best_subset, max_val, best_ranking_sum, best_dist_sum, best_boundbox_val, all_subset_rankings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70c48f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_pareto_only(simgraph):\n",
    "    simgraph_out = nx.Graph()\n",
    "    node_count = len(simgraph.nodes())\n",
    "    i2 = 0;\n",
    "    for i in range(0, node_count):\n",
    "        new_props = {}\n",
    "        props = simgraph.nodes[i]\n",
    "        if (props['TESTTAG'] == 1):\n",
    "            for k,v in simgraph.nodes[i].items():\n",
    "                new_props[k] = v\n",
    "                new_props['orig_id'] = i\n",
    "                \n",
    "            simgraph_out.add_nodes_from([(i2, new_props)])\n",
    "            i2+=1\n",
    "                \n",
    "    #for i in range(0, node_count):\n",
    "    #    for j in range(0, node_count):\n",
    "    #        if (i != j):\n",
    "    #            simgraph_out.add_edge(i,j)\n",
    "                \n",
    "    return simgraph_out    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51f47c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tests_by_ids(csv_filename,graph,chosen_set):\n",
    "    df = pd.read_csv(csv_filename)\n",
    "    output_testnames = map (lambda id: graph.nodes[id]['NAME'], chosen_set)\n",
    "    # Filter the dataframe by test ID as NAME field\n",
    "    return df[df['NAME'].isin(output_testnames)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877f7e02-01ed-4e6b-ac56-db2544cdafae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the surface and the graph between them\n",
    "def plot_graph_with_edges_from_subset(g, edge_set, elev, azim, ax_dist, dim_names, filename, dpi=300):\n",
    "    MAX_MARKER_SIZE = 10\n",
    "    MIN_MARKER_SIZE = 4\n",
    "    FONT_LABEL_SIZE=8\n",
    "    \n",
    "    x = np.array(list(map(lambda n: g.nodes[n]['d0'], g)))\n",
    "    y = np.array(list(map(lambda n: g.nodes[n]['d1'], g)))\n",
    "    z = np.array(list(map(lambda n: g.nodes[n]['d2'], g)))\n",
    "    # 3d spring layout\n",
    "    pos = np.vstack((x, y, z)).T\n",
    "    print(\"pos\\n\",pos)\n",
    "    # Extract node and edge positions from the layout\n",
    "    node_xyz = np.array([pos[v] for v in g])\n",
    "    \n",
    "    node_ranks = np.array(list(map(lambda n: (MIN_MARKER_SIZE + MAX_MARKER_SIZE * ranking_func(g, n))**2.0, g)))\n",
    "    \n",
    "    edge_id_set = itertools.combinations(edge_set, r=2)\n",
    "    #eset_l = list(edge_id_set)\n",
    "    #print(\"edge_id_set\\n\", eset_l)\n",
    "    edge_xyz = np.array([(pos[t[0]], pos[t[1]]) for t in edge_id_set])\n",
    "    print(\"edge_xyz\\n\",edge_xyz)\n",
    "\n",
    "    # Create the 3D figure\n",
    "    fig = plt.figure()\n",
    "    plt.rc('axes', labelsize=FONT_LABEL_SIZE) \n",
    "        \n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "    ax.axes.set_xlabel(dim_names[0])\n",
    "    ax.axes.set_ylabel(dim_names[1])\n",
    "    ax.axes.set_zlabel(dim_names[2])\n",
    "    #ax.axes.set_xlim3d(left=0, right=1) \n",
    "    #ax.axes.set_ylim3d(bottom=0, top=1) \n",
    "    #ax.axes.set_zlim3d(bottom=0, top=1) \n",
    "    ax.view_init(elev=elev, azim=azim)\n",
    "    ax.dist = ax_dist\n",
    "\n",
    "    # Plot the nodes - alpha is scaled by \"depth\" automatically\n",
    "    ax.scatter(*node_xyz.T, s=node_ranks, ec=\"w\")\n",
    "\n",
    "    # Plot the edges\n",
    "    for vizedge in edge_xyz:\n",
    "        ax.plot(*vizedge.T, color=\"tab:gray\")\n",
    "    \n",
    "    #_format_axes(ax)\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(filename, bbox_inches=\"tight\", dpi=dpi)\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d2bce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [8, 3.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60266f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters for the subset selection below\n",
    "# MAX_COST - maximum cost value allowed\n",
    "# lam - lambda parameter value\n",
    "# dims - chosen dimensions for the subset selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d5c82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_filename=\"/home/jharbin/eclipse-workspace/PALTesting/models/res/from-server/TestingPAL-coverage-2024_03_03_09_pop32_cutdown_256.modelscenario2-eddi-timebased-faults-coveragereduced-NONDOM-256.csv\"\n",
    "\n",
    "MAX_COST = 5\n",
    "lam = 1.0\n",
    "#dims = ['T1_TIME_MIDPOINT_MEAN', 'P1_PARAMETER_MEAN', 'T2_TIME_LENGTH_MEAN']\n",
    "dims = ['T1_TIME_MIDPOINT_MEAN', 'T2_TIME_LENGTH_MEAN', 'O0_TOTAL_COUNT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa651592-8200-485f-9894-0f4581794c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_count = len(dims)\n",
    "sim = create_sim_graph_from_data(csv_filename, dims)\n",
    "sim_pareto = filter_pareto_only(sim)\n",
    "phy, cost, best_ranking, best_distance_sum, best_boundvol, all_rankings = best_subset_via_powerset(sim_pareto, dim_count, lam, MAX_COST)\n",
    "print(\"Best selection:\" , phy,cost,best_ranking, best_distance_sum)\n",
    "\n",
    "elev = 50\n",
    "azim = 120\n",
    "ax_dist = 13\n",
    "pdf_filename = \"pw-subsetsel-lambda\" + str(lam) + \".pdf\"\n",
    "png_filename = \"pw-subsetsel-lambda\" + str(lam) + \".png\"\n",
    "dpi_png=600\n",
    "plot_graph_with_edges_from_subset(sim_pareto, phy, elev, azim, ax_dist, dims, pdf_filename)\n",
    "plot_graph_with_edges_from_subset(sim_pareto, phy, elev, azim, ax_dist, dims, png_filename, dpi_png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bbcc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tests_by_ids(csv_filename,sim_pareto,phy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d653e589-dc26-4fa4-bc87-2642a0741748",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92fe415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max ranking of all - should agree with Best selection ranking when lambda = 0\n",
    "from operator import itemgetter\n",
    "max(all_rankings, key=itemgetter(2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fb1767-45b3-40e2-9806-6b7d3e66b786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max distance sum - should agree when Best selection; max_distance_sum when lambda = 1\n",
    "from operator import itemgetter\n",
    "max(all_rankings, key=itemgetter(3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8aee7d6-fb6d-463b-bb41-f16e719f6e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max distance sum - should agree when Best selection; max_distance_sum when lambda = 1\n",
    "from operator import itemgetter\n",
    "max(all_rankings, key=itemgetter(4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575f4d68-d3f7-47f2-b0db-fbd275fb7777",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_pareto.nodes[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0092f2bc-4017-48cf-b2c2-7b3646829c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounding_box_all_dimensions(sim_pareto, [1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44da8193-cb9b-4f19-b062-19b09245fb9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2979d2f4-1ae3-4b56-aef5-1a646cad8283",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
