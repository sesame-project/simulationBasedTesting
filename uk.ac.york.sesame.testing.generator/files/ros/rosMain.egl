[%
	var mrs = Testing!TestingSpace.all().first().mrs;
	var launchFileLocation = mrs.launchFileLocation;
	var simulator = mrs.simulator;
	var topicsNodesPublish = Node.all().publisher.flatten();
	var topicsMetricsNeed = Metric.all().relatedTopics.flatten();
	topicsNodesPublish.println();
	topicsMetricsNeed.println();
%]

import java.util.HashMap;
import java.util.Properties;
import java.util.concurrent.TimeUnit;

import org.apache.flink.api.common.functions.FlatMapFunction;
import org.apache.flink.api.common.functions.MapFunction;
import org.apache.flink.api.common.serialization.SimpleStringEncoder;
import org.apache.flink.api.common.serialization.SimpleStringSchema;
import org.apache.flink.api.common.typeinfo.Types;
import org.apache.flink.connector.file.sink.FileSink; 
import org.apache.flink.core.fs.Path;
import org.apache.flink.streaming.api.datastream.*;
import org.apache.flink.streaming.api.datastream.DataStream;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.api.functions.sink.filesystem.rollingpolicies.DefaultRollingPolicy;
import org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer;
import org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer;
import org.apache.flink.util.Collector;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;

import uk.ac.york.sesame.testing.architecture.attacks.*;
import uk.ac.york.sesame.testing.architecture.ros.ROSSimulator;
import uk.ac.york.sesame.testing.architecture.config.ConnectionProperties;
import uk.ac.york.sesame.testing.architecture.data.*;

import metrics.custom.*;

public class [%=test.name.firstToUpperCase()%]_TestRunner {

	public static void main(String[] args) {
		
		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
		Properties properties = new Properties();
		properties.setProperty("bootstrap.servers", "localhost:9092");
		properties.setProperty("group.id", "test");
		
		DataStream<EventMessage> stream = env
			.addSource(new FlinkKafkaConsumer<EventMessage>("IN", new EventMessageSchema(), properties)).returns(EventMessage.class);
		
		DataStream<EventMessage> streamOut = env
				.addSource(new FlinkKafkaConsumer<EventMessage>("OUT", new EventMessageSchema(), properties))
				.returns(EventMessage.class);
		
		// Kafka Sink to OUT
		FlinkKafkaProducer<EventMessage> myProducer = new FlinkKafkaProducer<EventMessage>("OUT", // target topic
				new EventMessageSchema(), properties);
				
		// This connects the metrics via Kafka to the metrics monitoring on the SESAME tool
		FlinkKafkaProducer<MetricMessage> metricsProducer = new FlinkKafkaProducer<MetricMessage>(
		        "metricMessages",             // target topic
		        new MetricMessageSchema(),    // serialization schema
		        properties             // producer config
		      );
				
		stream.
		[%
			for (attack in test.attacks) {
				var flatMapString = produceFlatMapSignature(attack);
				%]
				[%=flatMapString%]
				[%
			}
		%]
		addSink(myProducer);
	
		[%
		if (simulator.isTypeOf(ROSSimulator)) { %]
		ROSSimulator rosSim = new ROSSimulator();
		ConnectionProperties cp = new ConnectionProperties();
		HashMap<String, Object> propsMap = new HashMap<String, Object>();
		propsMap.put(ConnectionProperties.HOSTNAME, "[%=simulator.hostname%]");
		propsMap.put(ConnectionProperties.PORT, [%=simulator.port%]);
		cp.setProperties(propsMap);
		
		// JRH: moved the simulation launcher outside of the thread to the main code
		HashMap<String, String> params = new HashMap<String,String>();
		params.put("launchPath", "[%=launchFileLocation%]");
		System.out.println("Simulator Starts");
		rosSim.run(params);
		rosSim.connect(cp);
		
		[% for (aTopic in topicsNodesPublish) { %]
		Thread subscriber_thread_[%=aTopic.name.replace("/","_")%] = new Thread() {
			public void run() {
				System.out.println("Subscriber [%=aTopic.name.replace("/","_")%] Starts");
				rosSim.consumeFromTopic("[%=aTopic.name%]", "[%=aTopic.type.name %]", true, "IN");
			}
		};
		subscriber_thread_[%=aTopic.name.replace("/","_")%].start();
		[% } %]
		
		[% for (aTopic in topicsMetricsNeed) { %]
		Thread subscriber_thread_[%=aTopic.name.replace("/","_")%] = new Thread() {
			public void run() {
				System.out.println("Subscriber [%=aTopic.name.replace("/","_")%] Starts");
				rosSim.consumeFromTopic("[%=aTopic.name%]", "[%=aTopic.type.name %]", true, "IN");
			}
		};
		subscriber_thread_[%=aTopic.name.replace("/","_")%].start();
		[% } %]

		
		Thread from_out_to_sim = new Thread() {
			public void run() {
				System.out.println("From out to sim starts");
				while (true) {
					ConsumerRecords<Long, EventMessage> cr = DataStreamManager.getInstance()
							.consume("OUT");
					for (ConsumerRecord<Long, EventMessage> record : cr) {
						String inTopic = record.value().getTopic().toString();
						String outTopic = rosSim.translateTopicNameForOutput(inTopic);
						System.out.println("OUT TO SIM: inTopic = " + inTopic + " -> " + outTopic);
						rosSim.publishToTopic(outTopic, record.value().getType(), record.value().getValue().toString());
					}
				}
			}
		}; 
		
		from_out_to_sim.start();
		
		// Generate keyed streams
		KeyedStream<EventMessage, String> topicKeyedIn = stream.keyBy(value -> value.getTopic());
		KeyedStream<EventMessage, String> topicKeyedOut = streamOut.keyBy(value -> value.getTopic());
		KeyedStream<EventMessage, String> testKeyedIn = stream.keyBy(value -> "[%= test.name %]");
		KeyedStream<EventMessage, String> testKeyedOut = streamOut.keyBy(value -> "[%= test.name %]");;
		
		// Stream metrics here
		[% for (sMetric in Testing!StreamMetric.all()) { %]
			[% if (sMetric.streams.size() == 2) {
				var stream1 = sMetric.streams.get(0);
				var stream2 = sMetric.streams.get(1); %]
				ConnectedStreams<EventMessage, EventMessage> [%= sMetric.name %]combinedStream = [%= streamJavaName(sMetric,stream1) %].connect([%= streamJavaName(sMetric,stream2) %]);
				DataStream<Double> [%= sMetric.name %]resStream = [%= sMetric.name %]combinedStream.process(new [%= sMetric.name %]Metric());
			[% } %]
			
			[% if (sMetric.streams.size() == 1) { 
				var stream = sMetric.streams.get(0); %]
				DataStream<Double> [%= sMetric.name %]resStream = [%= streamJavaName(sMetric,stream) %].process(new [%= sMetric.name %]Metric());
			[% } %]
			
			[* If the stream has a FileStreamResult, log it to a file *]
			[% if (sMetric.res.isTypeOf(Testing!FileStreamResult)) { 
				var filename = sMetric.res.filename;
				%] 

				final FileSink<String> [%= sMetric.name %]streamFileSink = FileSink
				    .forRowFormat(new Path("[%= filename %]"), new SimpleStringEncoder<String>("UTF-8"))
			    	.withRollingPolicy(
				        DefaultRollingPolicy.builder()
			            	.withRolloverInterval(TimeUnit.MINUTES.toMillis(150))
			            	.withInactivityInterval(TimeUnit.MINUTES.toMillis(50))
			            	.withMaxPartSize(1024 * 1024 * 1024)
				            .build())
					.build();
				[%= sMetric.name %]resStream.map(e -> e.toString()).sinkTo([%= sMetric.name %]streamFileSink);
			[% } %]
		[% } %]
		
		[* Add the topic metrics here *]
		
		[%  var parentCampaign = test.parentCampaign;
			var allMetrics = parentCampaign.metrics.clone();
		    for (sMetric in allMetrics.selectByKind(StreamMetric)) { %] 
			// Generate a message stream for all metrics
			DataStream<MetricMessage> metricMsg[%= sMetric.name %] = [%= sMetric.name %]resStream.map(d -> new MetricMessage("[%=test.name.firstToUpperCase() %]", "[%= sMetric.name %]", d));
		[% } %]
		
		
		[* Create the unioned metric stream and link to the producer *]
		[% 	if (allMetrics.size() > 0) {
			var firstMetric = allMetrics.removeAt(0); %]
		metricMsg[%= firstMetric.name%]
		
		[* One element has been removed from allMetrics - so compare against zero, not one! *]
		[% if (allMetrics.size() > 0) {
				for (metric in allMetrics) { %]
		.union(metricMsg[%= metric.name %])
				[% }
		} %]
				
		.addSink(metricsProducer);
		[% } %]
		
		
		try {
			env.execute();
		} catch (Exception e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}
		[%
		}
		%]
	}
}

[%

operation streamJavaName(sMetric, stream) {
	// TODO: Get comparison of enum working rather than using literal value
	// Metrics!MetricStateKeyedBy#TEST doesn't work
//	if (sMetric.keyedBy == 2) {
//		if (stream.isTypeOf(Testing!InputStream)) {
//			return "topicKeyedIn";
//		}
//	
//		if (stream.isTypeOf(Testing!OutputStream)) {
//			return "topicKeyedOut";
//		}
//	}
	
	
//	if (sMetric.keyedBy == 1) {
		if (stream.isTypeOf(Testing!InputStream)) {
			return "testKeyedIn";
		}
	
		if (stream.isTypeOf(Testing!OutputStream)) {
			return "testKeyedOut";
		}
//	}
}

// TODO: The if statement should be extended to construct other attacks - currently PacketLossNetworkAttack, BlackHoleFlatMap and RandomValueFromSetAttack are supported
operation produceFlatMapSignature(attack) {
	var flatmap = "";
	var aaList = attack.attackActivation;
	var startTime;
	var endTime;
	
	// TODO: currently, this only uses the first AttackActivation
	var aa = aaList.first();
	
	if (aa.isKindOf(AttackFixedTime)) {
		startTime = aa.startTime;
		endTime = aa.endTime;
	}
			
		
	if (attack.isTypeOf(Testing!PacketLossNetworkAttack)) {
		flatmap = "flatMap(new PacketLossFlatMap(\"" + attack.topicToAttack.name + "\", \"" + startTime + "\", \"" + endTime + "\", " + attack.frequency + ")).";
	} else if (attack.isTypeOf(Testing!BlackholeNetworkAttack)) {
		flatmap = "flatMap(new BlackHoleFlatMap(\"" + attack.topicToAttack.name + "\", \"" + startTime + "\", \"" + endTime + "\")).";
	} else if (attack.isTypeOf(Testing!RandomValueFromSetAttack)) {
		// TODO: set up proper random seed here
		flatmap = "flatMap(new " + attack.name + "FlatMap(\"" + attack.topicToAttack.name + "\", \"" + startTime + "\", \"" + endTime + "\"," + attack.seed + ")).";
	}
	
	return flatmap;
}
%]
